{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n# !pip install scikit-learn\n# !pip install tensorflow\n# !pip install seaborn\n\nimport tensorflow as tf\nfrom tensorflow.keras import models, layers\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, ReLU, Dropout\nimport h5py\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nimport os\n# DATASET_DIR = '../Dataset'\nBATCH_SIZE = 32\nIMAGE_SIZE = 256\nCHANNELS = 3\nEPOCHS = 5\n\ndataset = tf.keras.preprocessing.image_dataset_from_directory(\n    '/kaggle/input/nutrient-deficiency-dataset/Final_dataset',\n    shuffle = True,\n    image_size = (IMAGE_SIZE,IMAGE_SIZE),\n    batch_size = BATCH_SIZE,\n    # class_names=['Potato___Early_blight', 'Potato___healthy', 'Potato___Late_blight']  # Replace with your own class names\n)\nprint(len(dataset))\ndef get_dataset_partitions_tf(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n    ds_size = len(ds)\n\n    if(shuffle):\n      ds = ds.shuffle(shuffle_size, seed=10)\n\n    train_size = int(train_split * ds_size)\n    val_size = int(val_split * ds_size)\n\n    train_ds = ds.take(train_size)\n\n    val_ds = ds.skip(train_size).take(val_size)\n    test_ds = ds.skip(train_size).skip(val_size)\n    return train_ds, val_ds, test_ds\n\ntrain_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)\nclass_names = sorted(os.listdir('/kaggle/input/nutrient-deficiency-dataset/Final_dataset'))\nprint(len(test_ds))\n# print(test_ds)\nfrom keras.models import load_model\ntrained_model = load_model('/kaggle/input/nutrient-def-models/nutrient_def_model2.h5')\nscores = trained_model.evaluate(test_ds)\nprint(scores)\n\npredicted_labels = []\ntrue_labels = []\nfor inputs, labels in test_ds:\n#     print(inputs,labels,'\\n')\n    predicted = trained_model.predict(inputs)\n    predicted_labels.extend(predicted.argmax(axis=-1))\n    true_labels.extend(labels.numpy())\n\npredicted_labels = [class_names[i] for i in predicted_labels]\ntrue_labels = [class_names[i] for i in true_labels]\n    \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\nlabels = np.array(class_names)\ny_true = np.array(true_labels)\ny_pred = np.array(predicted_labels)\n\ncm = confusion_matrix(y_true, y_pred, labels=labels)\n\n# Heat Map \ndf_cm = pd.DataFrame(cm, index=labels, columns=labels)\nsns.heatmap(df_cm, annot=True, cmap='Blues')\nplt.xlabel('Predicted labels')\nplt.ylabel('True labels')\n# plt.show()\nplt.savefig('/kaggle/working/heat_map.png')\n\n# Bar Chart\nprecision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred)\nfig, ax = plt.subplots(figsize=(10, 6))  # set figure size for better visibility\nx = np.arange(len(class_names))\nwidth = 0.15  # reduce width of bars\nax.bar(x - width, precision, width, label='Precision')\nax.bar(x, recall, width, label='Recall')\nax.bar(x + width, f1, width, label='F1 score')\nax.set_xticks(x)\nax.set_xticklabels(class_names, rotation=45, ha='right')  # rotate and align xticklabels for better visibility\nax.set_xlabel('Class Names')\nax.set_ylabel('Scores')\nax.legend()\nplt.tight_layout()  # adjust spacing between subplots\nplt.savefig('/kaggle/working/bar_chart.png')\n\n# Confusion Matrix with normalised values\ncm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm_norm, display_labels=class_names)\ndisp.plot(cmap=\"Blues\")\n# plt.show()\nplt.tight_layout()\nplt.savefig('/kaggle/working/conf_mat_normalised.png')\n\n\ndef precision_score(tp, fp):\n    return tp / (tp + fp)\ndef recall_score(tp, fn):\n    return tp / (tp + fn)\ndef f1_score(p, r):\n    return 2 * p * r / (p + r)\ndef accuracy(tp, tn, fp, fn):\n    return (tp + tn) / (tp + tn + fp + fn)\n\nprint('\\n', *class_names)\nprint('\\n', cm, '\\n')\nfor i in range(len(class_names)):\n    tp = cm[i, i]\n    x = 0\n    for j in range(len(class_names)):\n        x += cm[j, i]\n    fp = x - tp\n    x = 0\n    for j in range(len(class_names)):\n        x += cm[i, j]\n    fn = x - tp\n    tn = len(true_labels) - tp - fp - fn\n\n    print('TP = ',tp,' TN = ', tn,' FP = ', fp,' FN = ', fn)\n    precision = precision_score(tp, fp)\n    recall = recall_score(tp, fn)\n    f1 = f1_score(precision, recall)\n    _accuracy = accuracy(tp, tn, fp, fn)\n    print(f'Class {class_names[i]}:\\n'\n          f'    Classification Accuracy  = {_accuracy:.4f}\\n'\n          f'    Precision = {precision:.4f}\\n'\n          f'    Recall    = {recall:.4f}\\n'\n          f'    F1-score  = {f1:.4f}\\n')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]}]}